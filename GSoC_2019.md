OpenCV Google Summer of Code ([GSoC 2019](https://summerofcode.withgoogle.com/organizations/5654472617885696/))
=======================================================


![OpenCV Ideas Page](https://cdn-images-1.medium.com/max/800/1*VLYFDUP-j-sZB9xphmJxcA.jpeg)

_This is an example from_ [_heartbeat.fritz.ai_](https://heartbeat.fritz.ai/real-time-object-detection-on-raspberry-pi-using-opencv-dnn-98827255fa60) _where Saumya Shovan Roy got DNN object detection working on a Raspberry Pi using OpenCV DNN_

-----------------

OpenCV Project Ideas List:
=========================

| Index | to | Ideas | Below |
| ------------------------ | ------------------------- | -------------- | ----------------- |
| [Circular Calibration](https://github.com/opencv/opencv/wiki/GSoC_2019#idea-calibration-patterns-using-circular-features) | [Data Augmentation](https://github.com/opencv/opencv/wiki/GSoC_2019#area-data-augmentation) [**1**](https://github.com/opencv/opencv/wiki/GSoC_2019/#idea-computer-vision-data-augmentation-module) [**2**](https://github.com/opencv/opencv/wiki/GSoC_2019#idea-3d-augmentation--april-tags) | [GPU backend for DNN](https://github.com/opencv/opencv/wiki/GSoC_2019/#idea-allow-the-opencv-deep-neural-net-module-dnn-to-work-with-gpus) | [Binary Neural Nets](https://github.com/opencv/opencv/wiki/GSoC_2019/#idea-enable-training-and-inference-with-binary-neural-networks) |
| [Model Zoo](https://github.com/opencv/opencv/wiki/GSoC_2019/#idea-model-zoo-curate-deep-nets-for-the-DNN) | [Point Coordinate Regression](https://github.com/opencv/opencv/wiki/GSoC_2019/#idea-point-coordinate-regression-and-dsac) | [Differential Rendering](https://github.com/opencv/opencv/wiki/GSoC_2019/#idea-create-a-differentiable-rendering-module-torchgeometryrender) | [Image Processing](https://github.com/opencv/opencv/wiki/GSoC_2019/#idea-differentiable-image-processing) | 
|[April Tags](https://github.com/opencv/opencv/wiki/GSoC_2019/#idea-add-april-tag-fiducial-detection-to-opencv) or [Geometric April Tags](https://github.com/opencv/opencv/wiki/GSoC_2019#idea-3d-augmentation--april-tags)| [Optical Flow](https://github.com/opencv/opencv/wiki/GSoC_2019/#idea-create-a-consolidated-optical-flow-module-optflow)| [Python OpenCV](https://github.com/opencv/opencv/wiki/GSoC_2019/#idea-improve-and-expand-python-version-of-opencv)| [Depth Fusion](https://github.com/opencv/opencv/wiki/GSoC_2019/#idea-kinectfusion-improvements)|
|[Face Landmarks](https://github.com/opencv/opencv/wiki/GSoC_2019/#idea-facial-landmark-detector)| [Boosted Cascades](https://github.com/opencv/opencv/wiki/GSoC_2019/#idea-a-universal-boosted-cascades-interface)| [Tutorials:](https://github.com/opencv/opencv/wiki/GSoC_2019/#area-tutorials) [**G**eneral;]() [**M**achine Learning](https://github.com/opencv/opencv/wiki/GSoC_2019/#idea-improve-machine-learning-tutorials-and-documentation)| [OpenCV GUI](https://github.com/opencv/opencv/wiki/GSoC_2019/#idea-improve-the-opencv-user-interface)|
| [DNN Quantization](https://github.com/opencv/opencv/wiki/GSoC_2019/#idea-add-quantization-and-pruning-functionality-opencv-dnn-module) | [DNN Super-Resolution](https://github.com/opencv/opencv/wiki/GSoC_2019/#idea-deep-learning-based-super-resolution-algorithms-based-on-opencv-dnn) | [Alpha Matting](https://github.com/opencv/opencv/wiki/GSoC_2019/#idea-deep-learning-based-alpha-matting) [**1**](https://github.com/opencv/opencv/wiki/GSoC_2019/#idea-deep-learning-based-alpha-matting) [**2**](https://github.com/opencv/opencv/wiki/GSoC_2019/#idea-computer-vision-based-Alpha-Matting)| [Deep Nets on Video](https://github.com/opencv/opencv/wiki/GSoC_2019/#idea-python-deep-learning-inference-on-video) |
| geometric vision | | | 

-----------------

### **How to Apply**

OpenCV is taking part in [GSoC 2019](https://summerofcode.withgoogle.com/organizations/5654472617885696/). Below is a list of ideas from the OpenCV [developers](https://github.com/opencv/opencv/wiki/ChangeLog#contributors), [staff](https://github.com/opencv/opencv/wiki/GSoC_2019/_edit#staff) and [Evolution Proposals](https://github.com/opencv/opencv/wiki/Evolution-Proposals). _**Note:** We have a pre-application [form](https://goo.gl/forms/eF8G5TYIYzTjSxAJ2) below prior to Mar 25, but you must also register with [GSoC](https://summerofcode.withgoogle.com/) and apply to OpenCV there between March 25-April 9. See our [timeline below](https://github.com/opencv/opencv/wiki/GSoC_2019#important-dates)_


1. **Requirements:**
   - You **must** already know how to program fluently in C++!
   - Some projects may instead specifically require Python, javascript or Matlab skills
   - Some projects may require knowledge of Deep Nets and perhaps one or more of the standard packages:
      - PyTorch, TensorFlow, MXNet. Familiarity with OpenCV's DNN ([here for code](https://github.com/opencv/opencv/tree/master/modules/dnn) and [here for samples](https://github.com/opencv/opencv/tree/master/samples/dnn)) and [ONNX](https://onnx.ai/) deep net exchange is a big plus
1. **Please familiarize yourself with the:** 
   1. [OpenCV Developer's site](https://github.com/opencv/opencv/wiki), the 
   1. [User's site](https://opencv.org/), read through our
   1. [Ideas List](https://github.com/opencv/opencv/wiki/GSoC_2019#opencv-project-ideas-list) to see which projects are of interest to you, and familiarize yourself with
   1. The [GSoC 2019 timeline](https://developers.google.com/open-source/gsoc/timeline)
1. **Sign up:** for the [OpenCV_GSoC_2019 mailing list](https://groups.google.com/d/forum/opencv-gsoc-2019) where you can ask questions, exchange and discuss ideas with students and mentors, get announcements etc.
1. **Fill out:** the [pre-application form](https://goo.gl/forms/eF8G5TYIYzTjSxAJ2) for the one or two (_maximum_) projects you are interested in.
1. **Optional steps mentors may take:**
   * Mentors may contact you for hangouts or other means of live interview
   * You may be asked for proof of coding
   * You will probably be asked for a full project plan
1. **How to enhance your application:**
   1. Contributing to OpenCV is a **big plus**. Some suggestions:
      1. Fixing an [bug/issue](https://github.com/opencv/opencv/issues) or
      1. Very advanced people can already start delivering code for the idea they like to their mentor
      1. More realistically and still **great**: REALLY learn some OpenCV function and contribute a well written tutorial on it

----
# Ideas:

1. ### Area: Calibration
   1. #### _IDEA:_ Calibration Patterns using Circular Features
      * ***Description:*** OpenCV currently allows checkerboard, Aruco, mixed and a basic circular calibration grid. Circular patterns have very good detectability across scale, but the Circular calibration feature in OpenCV is not complete because when a circle is viewed in perspective, the center of the circle is not at the center of mass. This introduces a systematic error into calibration with circular patterns. This can be corrected by compensating for perspective distortion.
      * ***Expected Outcomes:*** 
         * Review the papers on the topic in resources below.
         * Code up a circular calibration module that implements the adjusts the circle center for perspective distortion.
         * Extensive validation (using other patterns and the circular pattern) that shows the circular pattern returning expected intrinsic and distortion camera parameters.
         * Optimizing the module to run efficiently
         * Python interface to the module
         * Resources
            * [Geometric Correction of Circular Fiducials](https://hal-enpc.archives-ouvertes.fr/hal-00990239); direct [pdf link](https://hal-enpc.archives-ouvertes.fr/hal-00990239/document)
            * [Valication Code for Circular Correction](https://github.com/vicrucann/Kmat-virtual)
      * ***Skills Required:*** Solid C++, Coursework and/or experience in camera calibration. Python is a plus because we want calibration to be callable from Python. Mainly, calibration software depends on the details, so being detail oriented is critical as well as the willingness to write thorough test code. 
      * ***Mentors:*** Grace Vesom, Gholamreza Amayeh 
      * ***Difficulty:*** Medium
   
1. ### Area: Data Augmentation
   1. #### _IDEA:_ Computer vision data augmentation module
      * ***Description:*** Deep learning networks are hungry for data and data augmentation is one of the easiest ways to increase data variation. Augmentation could be as simple image flipping, cropping and scaling on up to more complicated transformations such style transfer using another deep learning network. For computer vision problems, OpenCV is often used for reading images in most of training scenarios, so why we'd like to enhance data reading with simple to use data augmentation techniques as well.
      * ***Expected Outcomes:***
         1. Analyze which image transformations are widely used for image classification, object detection, semantic and instance segmentation problems.
            - Things that help with data augmentation for training networks
               - Lighting functions
               - spherical or cylindrical views around a planar object
               - noise ...
               - for 3D point clouds
         1. Create a new OpenCV's module (or use an existing one such `datasets` or `dnn`?) with at least the following functionality:
             - Provide an API to apply single transformations to an Image or batch of Images, Rectangles (i.e. for ground truth for object detection), Masks.
             - Let users combine different transformations in the class object which can apply them with some probability.
             - Custom data transformations which can be included in the augmentation classes.
         1. Write tutorials targeting on Python wrappers due it's the most popular language supported by different DL frameworks right now.
             - These should in particular show use with PyTorch and TensorFlow.
      * ***Skills Required:*** Experience in image processing and deep learning networks training for computer vision problems.
      * ***Mentors:*** Dmitry Kurtaev
      * ***Difficulty:*** Medium

   2. #### _IDEA:_ 3D Augmentation & April Tags
      * ***Description:*** 3D computer vision related data is represented mainly in two formats: volumetric data and point clouds. It is usually jointly combined with 2D data processing approaches and 3D approaches for semantic inference and fusion. In this project, we focus on contributing 3D semantic processing modules without dependence of heavy deep architectures. One application would be the April Tags recognition task.
      * ***Expected Outcomes:***
         1. Modify [TSDF-Fusion](https://github.com/andyzeng/tsdf-fusion) (_**T**runcated **S**igned **D**istance **F**unction-Fusion_) to produce 3D scenes (point clouds) from a sequence of depth images.
         1. On top of TSDF Fusion, implement [PCN](https://www.cs.cmu.edu/~wyuan1/pcn/)-like architecture for 3D completion from depth images. Try to make it more efficient by getting rid of convolutional operations for 3D data.
         1. C++/CUDA based 3D visualization APIs which are capable for rendering points clouds in the form of .ply or .obj files into high-quality mesh models with realistic shadows.
                        * (Additional) Implement AprilTag for full 6 DOF localization of features from a single image. Try to solve problems introduced by occlusion and bad lighting conditions.
         * resources:
            * [TSDF-Fusion](https://github.com/andyzeng/tsdf-fusion)
            * [PCN](https://www.cs.cmu.edu/~wyuan1/pcn/)
            * [AprilTag](http://people.csail.mit.edu/kaess/apriltags/)
            * [PointNet](https://github.com/charlesq34/pointnet)
            * [FoldingNet](https://arxiv.org/abs/1712.07262)
      * ***Skills Required:*** Experience in 3D data processing and linear algebra. Good at C++ and familiar with CUDA. Students should be able to understand the basic idea behind 3D point clouds deep learning approaches from basic PointNet.
      * ***Mentors:*** Yida Wang
      * ***Difficulty:*** Medium-Hard


1. ### Area: Deep Learning
   1. #### _IDEA:_ Allow the OpenCV Deep Neural Net Module (DNN) to work with GPUs
      * ***Description:*** The [OpenCV Deep Neural Network (DNN) Module](https://github.com/opencv/opencv/tree/master/modules/dnn) takes [deepnets found on the net]((https://github.com/opencv/opencv/wiki/Deep-Learning-in-OpenCV)) and runs them [5x faster than Pytorch or Tensorflow](https://github.com/opencv/opencv/wiki/DNN-Efficiency) on CPUs. Programmers find DNN [simple to use with powerful results](https://www.learnopencv.com/hand-keypoint-detection-using-deep-learning-and-opencv/). But, DNN is missing an NVidia GPU backend. This project aims at adding that missing GPU backend. 
      * ***Expected Outcomes:*** 
         * Developed plan to port the existing CPU backend to support GPU
            * Review tools [NVidia here](https://developer.nvidia.com/how-to-cuda-c-cpp), [Kokkos here](https://github.com/kokkos/kokkos), [RAJA here](https://github.com/LLNL/RAJA), [OpenCL here](https://www.khronos.org/opencl/), and [CUDA here](https://developer.nvidia.com/cuda-zone).
         * Implemented the new GPU backend for DNN
         * A test suite that compares CPU results with GPU results and makes sure they are close 
         * Performance as fast or faster than native use of nets on GPUs with TensorFlow and Pytorch
         * Resources
            * In general, you can leverage the [CUDA backend for Torch](https://pytorch.org/docs/stable/cuda.html) or DLib (Mentor has info) 
            * [DNN Module](https://github.com/opencv/opencv/tree/master/modules/dnn)
            * [DNN Tutorials](https://docs.opencv.org/master/d2/d58/tutorial_table_of_content_dnn.html)
            * [DNN Wiki -- what's in it](https://github.com/opencv/opencv/wiki/Deep-Learning-in-OpenCV)
            * [DNN Efficiency](https://github.com/opencv/opencv/wiki/DNN-Efficiency)
            * [DNN TensorFlow API](https://github.com/opencv/opencv/wiki/TensorFlow-Object-Detection-API)
            * [DNN Backend Description](https://github.com/opencv/opencv/wiki/Intel%27s-Deep-Learning-Inference-Engine-backend)
      * ***Skills Required:*** 
          * **Must have C++ mastery**
          * Good to have:
             * Python and python interface tools for C++ code, 
             * GPU/Cuda working experience, 
             * coursework or professional work with Deep Nets, 
             * Addional plus if you've optimized code before.
      * ***Mentors:*** Davis King (Dlib creator)
      * ***Difficulty:*** Medium-Hard (not hard if you know the tools/have worked with GPUs and C++ before)
   1. #### _IDEA:_ Enable Training and Inference with Binary Neural Networks
      * ***Description:*** Implement elementary building blocks for binary convolutional neural networks (binary activations and binary weights) for CPU with predictor and trainer modules.
      * ***Expected Outcomes:*** 
         * Inference module for binary convolutional layers.
         * Trainer module for training ensemble of the networks.
         * Exporter to generate self-contained network code with parameters (weights, etc.)
         * Resources
            * paper: https://arxiv.org/abs/1602.02830
            * paper: https://arxiv.org/abs/1809.03368 
            * paper: https://arxiv.org/abs/1603.05279
      * ***Skills Required:*** Skills Required: Coding in C/C++, speed optimization, multi-threading, random number generators, probabilities, Bayesian inference.
      * ***Mentors:*** Michael Tetelman
      * ***Difficulty:*** Medium/Hard

   1. #### _IDEA:_ Model Zoo Curate deep nets for the DNN 
      * ***Description:*** The [DNN module](https://docs.opencv.org/trunk/d6/d0f/group__dnn.html) in OpenCV allows for accomplishing powerful high end vision tasks with just a [few lines of code](https://www.pyimagesearch.com/2017/08/21/deep-learning-with-opencv/). The goal of this project is to curate more models for ease of use by the OpenCV DNN module and put them in a place that they can be easily accessed such as LFS on Git. The mentor/admins will formalize the storage place.
      * ***Expected Outcomes:*** 
         * Read through the list of known to work models and major deepnet models in the resource list below. Come up with a target list of 6 new neural network models to add. 
         * For each deepnet model in turn
            * Use ONNX or other to allow the model to be run in DNN
            * Write a concise sample code and tutorial showing loading and use of that deepnet model
            * We will allocate a data store for your DNN enabled models so that they may be called by DNN and run. Put your models and other known to run models in this data store.
         * Resources
            * [DNN Tutorial](https://docs.opencv.org/master/d2/d58/tutorial_table_of_content_dnn.html)
            * [List of deepnets known to work with DNN](https://github.com/opencv/opencv/wiki/Deep-Learning-in-OpenCV)
            * [List of major deepnet models](https://github.com/kjw0612/awesome-deep-vision) 
            * [Code for DNN Module](https://github.com/opencv/opencv/tree/master/modules/dnn)
            * [LFS on Github](https://git-lfs.github.com/)
      * ***Skills Required:*** Coding in C++ and Python. Experience with deep neural networks.
      * ***Mentors:*** Stefano Fabri
      * ***Difficulty:*** Easy

   1. #### _IDEA:_ Add quantization and pruning functionality OpenCV DNN module
      * ***Description:*** "Learning compact models for object detection" added  SqueezeDet and SqueezeNet models to OpenCV repository. But OpenCV DNN module is still lacks high-level quantization and pruning functionality. Project also includes implementation of re-training (fine-tuning) of quantized and/or pruned models.
      * ***Expected Outcomes:*** 
         * 8-bit and 16-bit quantization implementation 
         * Iterative pruning with controlled by target sparsity
         * Provide examples of quantized and prunned network and fine-tune it (base is AlexNet or other classification architecture)
         * Provide evaluation of original network and compressed one (accuracy and speed)
         * Additional goals
            * N-bit quantization 
            * Different operation types as minifloat, dynamic fixed point etc.
            * Further model compression encoding/decoding with Huffman coding
         * Resources
            * https://arxiv.org/pdf/1806.08342.pdf
            * https://arxiv.org/pdf/1611.06440.pdf
      * ***Skills Required:*** Very good C++ coding skill, experience in Deep Learning area more than just tutorial, basic Computer Vision knowledge
      * ***Mentors:*** Tyan Vladimir
      * ***Difficulty:*** Medium-Hard 

   1. #### _IDEA:_ Deep Learning based Super-Resolution algorithms based on OpenCV DNN
      * ***Description:*** Project aims to build a super-resolution (SR) module inside OpenCV. Most probably base SR algorithms will be some Deep Learning algorithms (FSRCNN and EDSR) as recovering accuracy of DL algorithms is much better. But Computer Vision based algorithms can also taken in consideration (A+ and etc.) if their usefulness is proven in terms except accuracy. 
      * ***Expected Outcomes:*** 
         * Build Super-Resolution module and implement interface for running different SR algorithms.
         * Add SR datasets to OpenCV datasets module
         * Implement FSRCNN algorithm (fast one) and train model on SR datasets
         * Implement EDSR algorithm (accurate one) and train model on SR datasets
         * Experiments and comparison of different models along with simple bicubic interpolation (or resize?) 
         * Additional goals
            * Implement Computer Vision SR algorithm (A+ and etc.)
         * Resources
            * https://arxiv.org/pdf/1608.00367.pdf
            * https://arxiv.org/pdf/1707.02921.pdf
            * https://www.vision.ee.ethz.ch/publications/papers/proceedings/eth_biwi_01165.pdf
      * ***Skills Required:*** Good C++ coding skill, experience in Deep Learning area, experience in  Computer Vision area
      * ***Mentors:*** Tyan Vladimir
      * ***Difficulty:*** Medium

   1. #### _IDEA:_ Deep learning based alpha matting
      * ***Description:*** Project aims at generating a large training dataset for alpha matting, training the model and converting the model to ONNX to be used with OpenCV's DNN module.
      * ***Expected Outcomes:*** 
         * A large dataset which can be used to train models of alpha matting. 
         * Implement the paper: ["Deep Image Matting"](https://arxiv.org/abs/1703.03872) by Ning Xu et al.
         * Trained model by the use of the generated dataset
         * Experiments comparing results to existing alpha matting algorithms at [alphamatting.com](http://alphamatting.com/index.html)
         * Convert model to ONNX and provide a running example in OpenCV's DNN module
         * Resources
            * [alphamatting.com Comparison of many methods, datasets etc](http://alphamatting.com/index.html)
      * ***Skills Required:*** Excellent C++ and Python coding skills, Experience in training deep learning models in Tensorflow/Pytorch, Experience in Computer Vision, Experience in Deep Learning
      * ***Mentors:*** Sunita Nayak
      * ***Difficulty:*** Medium-Hard

   1. #### _IDEA:_ Computer Vision based Alpha Matting
      * ***Description:*** Project aims to integrate some of the best computer vision based best alpha matting algorithms into OpenCV. 
      * ***Expected Outcomes:*** 
         * Two different kinds of alpha matting options in OpenCV
         * Experiments comparing results to existing alpha matting algorithms at [alphamatting.com](http://alphamatting.com/index.html)
         * Implement the paper: ["A Global Sampling Method for Alpha Matting"](http://mmlab.ie.cuhk.edu.hk/archive/2011/cvpr11matting.pdf) by Kaiming He et al.
         * Implement the paper: ["Designing Effective Inter-Pixel Information Flow for Natural Image Matting"](https://arxiv.org/pdf/1707.05055.pdf) by Yagiz et. al."
         * Resources
            * [alphamatting.com](http://alphamatting.com/index.html) Comparison of many methods, datasets etc
      * ***Skills Required:*** Excellent C++ and Python coding skills, Experience in Computer Vision
      * ***Mentors:*** TBD
      * ***Difficulty:*** Medium-Hard

   1. #### _IDEA:_ Python deep learning inference on video
      * ***Description:*** OpenCV's [DNN module](https://docs.opencv.org/trunk/d6/d0f/group__dnn.html) allows high-level inference on individual images. But, performing inference on video requires producing much boilerplate code and skills not directly relevant to computer vision. The goal of this project is to develop a high-level helper class in python to perform optimized inference on videos (eg, pose detection, emotion detection) with data storage (eg, output and bounding boxes) in dataframes for easy access.
      * ***Expected outcomes:***
         * Review the papers on the topic in the resources below
         * Define and implement an API for proposed methods
         * Optimize batch processing of video input for neural networks
         * Implement the [Model Zoo](https://github.com/opencv/opencv/tree/master/samples/dnn) for video use cases
         * Handle optimal neural network inference output for further processing
         * Write examples and tutorials
         * Resources
            * [DNN Tutorial](https://docs.opencv.org/master/d2/d58/tutorial_table_of_content_dnn.html)
            * [List of DNNs](https://github.com/opencv/opencv/wiki/Deep-Learning-in-OpenCV)
            * [List of major DNN models](https://github.com/kjw0612/awesome-deep-vision)
      * ***Skills Required:***
         * Coding in Python. Experience with deep neural networks.
      * ***Mentors:*** Justin Shenk
      * ***Difficulty:*** Easy/Medium

1. ### Area: Differential operators
   1. #### _IDEA:_ Point Coordinate regression and DSAC.
      * ***Description:*** The task is to Implement a differentiable point coordinate regression and differentiable RANSAC into PyTorch Geometry. Open call to propose a differentiable decomposeHomography and help functions for R and T. Context: PyTorch Geometry is a partial reimplementation of OpenCV operators in a differentiable setup.
      * ***Expected Outcomes:*** 
         * Define and implement an API for proposed methods into PyTorch Geometry.
         * Define and implement DSAC as a generic framework (if possible) to the model (homography, pose, line, etc).
         * Provide unit test, gradient check tests.
         * Write sphinx documentation.
         * Write examples and notebook tutorials.
         * Resources
            * PyTorch Geometry https://github.com/arraiy/torchgeometry
            * point coordinate regression DSNT https://arxiv.org/abs/1801.07372 
https://github.com/anibali/dsntnn
            * differentiable randsac dsac https://github.com/vislearn/DSACLine
      * ***Skills Required:*** experience in geometry, computer vision and Python. You must know how to code using PyTorch and understanding about deep neural networks and the autograd engine.
      * ***Mentors:*** Clément Pinard http://perso.ensta-paristech.fr/~pinard/#
      * ***Difficulty:*** Medium/Hard

   1. #### _IDEA:_ Create a differentiable rendering module “torchgeometry.render”
      * ***Description:*** The task is to create a dedicated module into the PyTorch Geometry package based on the existing [Neural 3D Mesh Renderer framework](https://github.com/daniilidis-group/neural_renderer). Explore the framework and propose a solid API  with all the operators in order to provide as much as possible generic operators to solve computer graphics problems. Context: PyTorch Geometry is a partial reimplementation of OpenCV operators in a differentiable setup.
      * ***Expected Outcomes:*** 
         * Create a new module in torch geometry and propose an extens API based on the existing code.
         * Provide unit test, gradient check tests.
         * Write sphinx documentation.
         * Write examples and notebook tutorials.
         * Resources
            * PyTorch Geometry https://github.com/arraiy/torchgeometry
            * https://github.com/daniilidis-group/neural_renderer
      * ***Skills Required:*** experience in computer graphics, computer vision and Python. You must know how to code using PyTorch and understanding about deep neural networks and the autograd engine.
      * ***Mentors:*** Anatoly Baksheev
      * ***Difficulty:*** Medium/Hard

   1. #### _IDEA:_ Differentiable Image Processing
      * ***Description:*** Expand the existing PyTorch Geometry image processing module “torchgeometry.image”. The idea is to analyze what in OpenCV can be reimplemented in PyTorch in a differentiable manner and coexist with the framework. This will allow to run end-to-end Computer Vision pipelines reusing the computational graph, optimize with JIT or Tensor Comprehensions, run in distributed, etc. Context: PyTorch Geometry is a partial reimplementation of OpenCV operators in a differentiable setup.
      * ***Expected Outcomes:*** 
         * Explore the OpenCV API and propose what methods can be reimplemented fulfilling the above requirements.
         * Explore what’s in tensorflow image that can be used as a base API.
         * Match as much as possible OpenCV API.
            * Some ideas: sobel, laplacian filters, morphologic operators, color space conversions, etc.
         * Provide unit test, gradient check tests.
         * Write sphinx documentation.
         * Write examples and notebook tutorials.
         * Resources
            * PyTorch Geometry https://github.com/arraiy/torchgeometry
            * https://torchgeometry.readthedocs.io/en/latest/image.html
            * https://docs.opencv.org/master/d7/dbd/group__imgproc.html
      * ***Skills Required:*** experience in computer vision, and Python. You must know how to code using PyTorch and understanding about deep neural networks and the autograd engine.
      * ***Mentors:*** Edgar Riba
      * ***Difficulty:*** Medium/Hard

1. ### Area: Fiducials
   1. #### _IDEA:_ Add April Tag Fiducial detection to OpenCV
      * ***Description:*** April Tags are fiducial tabs that allow a geometric relation to camera pose via the 4 corners of the tags while yielding over 500 to several thousand uniquely readable tag patterns with error detecting codes. They are used extensively in camera calibration, object tracking, and robotics. They can be slow and hard to detect however. Add April Tags to OpenCV in a highly detectable and computationally efficient way by training MNet to recognize the tags and their corners and then using the April net algorithm at only one scale to find and confirm the ID of the tag.
      * ***Expected Outcomes:*** 
         * Train MNet to segment April tags to high performance under many views and lightings (Mentor will help with this)
            * It will detect corners in clockwise manner (even if 30% occluded)
            * It will detect ID even if 30% occluded
         * Move network into DNN
         * Use MNet to detect the ID and corners of tags, resize the tag to a canonical size and pass the corner locations and ID to the April Tag algorithm.
         * Modify the April Tag algorithm to take advantage of just one detection at a standard size and orientation together with an expected ID.
         * Resources
            * [April Tag paper](http://april.eecs.umich.edu/papers/details.php?name=olson2011tags)
            * [April Tags are described here](http://people.csail.mit.edu/kaess/apriltags/)
            * [April Tag C++ Code](https://github.com/swatbotics/apriltags-cpp)
            * [Academic Paper describing MNet](http://cdn.iiit.ac.in/cdn/cvit.iiit.ac.in/images/ConferencePapers/2017/jan_M-NET.pdf)
      * ***Mentors:*** Gary Bradski
      * ***Skills Required:*** Must and have experience using C++, Python and deep nets.
      * ***Difficulty:*** Hard. Must be able to train deep nets and use ONNX or other to port to DNN curated nets and then add a method for feeding in detected tags to the April tag algorithm (ported to OpenCV).

1. ### Area: Geometric Vision
   1. #### _IDEA:_ Create a Consolidated Optical Flow Module "optflow"
      * ***Description:*** Create a dedicated `optflow` module in the main repository consolidating the best available (within the library) collection of sparse and dense optical flow algorithms. We have LK optical flow, various sparse algorithms and the classical Farneback algorithm along with the better DIS optical flow. There may be some deep optical flow that's available in [OpenCV dnn samples](https://github.com/opencv/opencv/tree/master/samples/dnn).
      * ***Expected Outcomes:*** 
         * rename the [optflow module in opencv_contrib](https://github.com/opencv/opencv_contrib/tree/master/modules/optflow) to `optical_flow_experimental` 
         * Select the best optical flow modules (move those out of the former optflow in opencv_contrib)
         * Make a base class with standard method from which all optical flow estimators will derive. Some attempts to do that can already be found in [the video module](https://github.com/opencv/opencv/tree/master/modules/video)
         * Even though we consolidate API and move to the uniform object-oriented API, we need to keep the old API for backward compatibility (e.g. `cv::computeOptFlowFarneback` etc.).
         * Resources
            * [The feature request for this](https://github.com/opencv/opencv/wiki/OE-18.-Module-Optflow)
            * [The optical flow feature request](https://github.com/opencv/opencv/issues/11013)
            * [The optflow module in opencv_contrib](https://github.com/opencv/opencv_contrib/tree/master/modules/optflow) that includes some new optical flow algorithms.
      * ***Skills Required:*** mastery plus experience coding in C++, college course work in vision that covers optical flow, python. Best if you have also worked with deep neural networks.
      * ***Mentors:*** Vadim Pisarevsky
      * ***Difficulty:*** Medium (if you've worked with vision/opencv before)

1. ### Area: Programming Language/Web
   1. #### _IDEA:_ Improve and Expand Python Version of OpenCV
      * ***Description:*** The task is to create wrappers / code / tutorials for important modules and update / improve / expand existing tutorials for Python. This includes improving the documentation of newly added modules if required.
      * ***Expected Outcomes:*** 
         1. Add Python Wrappers for functions not present.
         1. Add python code for samples written in C++ only . [ C++ Samples ](https://github.com/opencv/opencv/tree/master/samples/cpp) , [ Python Samples ](https://github.com/opencv/opencv/tree/master/samples/python)
         1. Add tutorials for which Python code is already present as in [these python samples ](https://github.com/opencv/opencv/tree/master/samples/python)
         1. Combine Tutorials for C++ / Python etc into single directory and format the tutorial as shown in [this tutorial](https://docs.opencv.org/4.0.0/d1/d73/tutorial_introduction_to_svm.html). Details of documentation are [present here](https://github.com/opencv/opencv/blob/master/doc/tutorials/introduction/documenting_opencv/documentation_tutorial.markdown).
      * ***Skills Required:*** Mastery of C++ and python. Experience of creating python interface to C++ code. Fluent in written English.
      * ***Mentors:*** Ankit Sachan
      * ***Difficulty:*** Medium

   1. #### _IDEA:_ Improve the performance of JavaScript version of OpenCV (OpenCV.js)
      * ***Description:*** OpenCV.js makes OpenCV functions available to JavaScript developers by compiling its C++ implementation to WebAssembly (or Asm.js) and exposing them through a JavaScript binding. However the current version of OpenCV.js only runs in single thread and doesn't use SIMD instructions. This causes the performance of OpenCV.js is far below the native version and prevents some real-time use cases to be deployed in web browser. This task aims to improve the performance of OpenCV.js by exploiting parallelism of CPU. This requires to port the parallel implementations of OpenCV source code to web by leveraging Threads and SIMD features of WebAssembly.
      * ***Expected Outcomes:*** 
         * Speedup OpenCV.js by multi-threading
         * Speedup OpenCV.js by SIMD (using WASM)
         * Create OpenCV.js benchmark and profile the performance on multiple platforms
         * Create a real-time demo by leveraging parallel version of OpenCV.js
         * Resources
            * [OpenCV.js paper (including earlier experiments for parallelism by Web Worker and SIMD.js](https://dl.acm.org/citation.cfm?id=3204949.3208126)
            * [WebAssembly Threads](https://www.chromestatus.com/feature/5724132452859904)
            * [WebAssembly SIMD](https://www.chromestatus.com/feature/6533147810332672)
            * [JavaScript module](https://github.com/opencv/opencv/tree/master/modules/js)
            * [OpenCV.js tutorials](https://docs.opencv.org/master/d5/d10/tutorial_js_root.html)
      * ***Skills Required:*** C++, JavaScript, HTML, WebAssembly, performance optimization, multi-threading and SIMD. Fluent in written English.
      * ***Mentors:*** Ningxin Hu
      * ***Difficulty:*** Medium 

1. ### Area: SLAM / Camera Pose / RGBD / 3D reconstruction
   1. #### _IDEA:_ KinectFusion improvements
      * ***Description:***
         We have a KinectFusion 3d reconstruction algorithm which works reasonably well. However its practical use is limited by the list of reasons:
         - its space is limited and cannot extend as the camera moves
         - (connected to previous one) its space representation consumes too much memory
         - it cannot process non-rigid scenes like with living people or animals (even slight moves leaves running average artifacts)

         That's why there are 2 main ways of improvement:

         - Large scale implementations of the algorithm like Kintinuous or KinFu Large Scale
         - Implementing DynamicFusion which handles non-rigid scenes (seems more preferable because of already existing code from GSoC 2017)
         It's up to participant what way to choose.
      * ***Expected Outcomes:*** 
         GSoC participant is expected to build a version of the chosen algorithm that conforms to OpenCV standards:
         - it has (maybe slow) CPU version
         - it has tests w/ captured depth or rendered scene as it's done in OpenCV's KinFu version
         - it builds, it works and produces fine results at least on one dataset (better if this works in live mode)
         - it has as few dependencies as it is possible (ideal case is no dependencies outside of OpenCV)

         This should be done inside `rgbd` module as a separate class based on existing KinFu class.
         The set of methods may be extended by the ones to export resulting 3d model in any form (at least points+normals).

         * Resources
           - [DynamicFusion](https://grail.cs.washington.edu/projects/dynamicfusion/papers/DynamicFusion.pdf) which is able to handle non-rigidness by introducing local transformations
           - [Kintinuous](http://www.cs.nuim.ie/research/vision/data/rgbd2012/) large-scale version of KinFu which is based on pose-graph
           - [KinFu Large Scale](http://pointclouds.org/documentation/tutorials/using_kinfu_large_scale.php) this one is based on marching cubes
           - [rgbd module](https://github.com/opencv/opencv_contrib/tree/master/modules/rgbd) containing existing KinFu implementation
           - [previous attempt to make DynamicFusion](https://github.com/opencv/opencv_contrib/pull/1349)
           - [Dataset for non-rigid scene](http://lgdv.cs.fau.de/uploads/publications/data/innmann2016deform/umbrella_data.zip)
      * ***Skills Required:*** good understanding of 3d math, experienced in C++, experience in computer vision or image processing (at least one successful project), a lot of patience
      * ***Mentors:*** Rostislav Vasilikhin
      * ***Difficulty:*** from Hard to Extreme (based on the fact that there was one unsuccessful attempt in the past GSoC)
   1. #### _IDEA:_ _This is a placeholder:_ We may add an idea for Mobile SLAM 2/13/2019
      * ideas from http://imagine.enpc.fr/~moulonp/openMVG/coreFeatures.html

1. ### Area: Tracking, Human Tracking, and Segmentation
   1. #### _IDEA:_ Facial Landmark Detector
      * ***Description:*** Facial feature detection and tracking is a high value area of computer vision since humans are interested in what humans are paying attention to, feeling, and enhancing face pictures in selfies etc. At this point, we feel this should just become a standard "built in" ability that computer vision users can just call/rely on. OpenCV already has some code available on for Facial Landmark detection, see [Tutorial on Facial Landmark Detector API](https://docs.opencv.org/4.0.0/d5/d47/tutorial_table_of_content_facemark.html) and  [Tutorials for face module](https://docs.opencv.org/4.0.0/de/d27/tutorial_table_of_content_face.html), but much progress has been made that we want to make available. The task is to create a Facial Landmark detector model with the following requirements:
      * ***Expected Outcomes:*** 
         * For mobile, make available a smaller model with lesser points ( e.g. 5 instead of 68 )
         * Run at better Accuracy than Dlib
         * Face Stabilization ( filtering and optical flow )
         * Add it to the Python API
         * Resources
            * https://docs.opencv.org/4.0.0/d5/d47/tutorial_table_of_content_facemark.html
            * https://docs.opencv.org/4.0.0/de/d27/tutorial_table_of_content_face.html
            * https://github.com/opencv/opencv_contrib/tree/master/modules/face
      * ***Skills Required:*** mastery level C++ and Python, college course work in Computer Vision that includes work on face features. Best if you have worked with deep networks before.
      * ***Mentors:*** Satya Mallick
      * ***Difficulty:*** Medium

   1. #### _IDEA:_ A universal boosted cascades interface
      * ***Description:*** Boosted cascades, before the era of deep learning, have long been the state-of-the-art for object detection and decision learning. When moving to OpenCV4 future releases, the plan is to remove them because of the old C-API backend and the tons of issues with the current implementation. This project will focus on re-implementing the boosted cascades, through an open and universal interface, that will allow applying these techniques, combined with newer feature generation algorithms like for example CNNS.
      * ***Expected Outcomes:*** 
         * Re-implement the boosted cascades / softcascades basic algorithm into OpenCV4.0 
         * Provide universal feature adding functionality: more than the previous HAAR/LBP/HOG 
         * Provide training, detection and evaluation interfaces
         * Resources
            * https://docs.opencv.org/3.4/dc/d88/tutorial_traincascade.html
            * https://github.com/opencv/opencv/tree/master/apps
      * ***Skills Required:*** efficient in C++ coding, college course work in classic computer vision, mediate experience in deep learning can help to include them as feature generators
      * ***Mentors:*** Steven Puttemans
      * ***Difficulty:*** Medium

1. ### Area: Tutorials

   1. #### _IDEA:_ General Tutorials with Video
      * ***Description:*** Videos have proven to be one of the most effective and engaging tools for learning.
In this GSoC project, we will be adding videos to the existing OpenCV tutorials.
The goal of these videos is to introduce the Computer Vision theoretical concepts behind each tutorial.
We will provide our users with a better understanding of the theory and hopefully they will achieve better results when implementing their own projects.
         * Additionally, we aim for our documentation to be versatile, hence, a second goal of this project is to keep working towards multi-language tutorials (C++, Python, Java, ...)
and work on the associated tools.
      * ***Expected Outcomes:*** 
         1. Add 1 youtube video to each tutorial (set of tutorials to be defined)
         1. Add Java and Python version to the currently C++ only tutorials
         1. Add quick navigation (previous/next tutorial) to all the tutorials
         1. Contribute to the merge of the python documentation with the general one
      * ***Skills Required:*** C++, Python, Java, Computer Vision, English.
      * ***Mentors:*** Joao Cartucho, Steven Puttemans _(if more than one student)_
      * ***Difficulty:*** Medium

   1. #### _IDEA:_ Improve Machine Learning Tutorials and Documentation
      * ***Description:*** The **D**eep **N**eural **N**etwork (**DNN**) module is new and light on good tutorials. The **M**achine **L**earning (**ML**) Module is old and needs a tutorial refresh. The task is to create tutorials (code example applications and describe) for the machine learning/deep neural network modules and to update / improve / expand existing tutorials ( Mostly in C++ ) for the main OpenCV module as well as some opencv_contrib modules. This includes improving the documentation of newly added modules if required.

      * ***Expected Outcomes:*** 
         1. Write tutorials for DNN Module. 
            1. Code examples and create a tutorial on how the DNN module is structured and create a video explaining the important functions in the DNN module.
            1. Add code samples and write-ups on the usage of ONNX models.
            1. Search for real-time state-of-the-art models and port it to OpenCV.
         1. Improve and expand write-ups / videos for sample code already present in the repository but no tutorials. E.g.:
            1. [DNN](https://github.com/opencv/opencv/tree/master/samples/cpp)
               1. Image Classification using Tensorflow
               1. Object Detection using Tensorflow API
               1. Semantic Segmentation
               1. Image Colorization
               1. Neural Style Transfer
               1. OpenPose
            1. C++ code samples present in [opencv repo](https://github.com/opencv/opencv/tree/master/samples/cpp). e.g.
                  1. DIS Optical Flow
         1. Add code samples and write-ups for using different algorithms e.g.
            1. ML module
               1. Normal Bayes Classifier
               1. Decision Trees
               1. Random Forests
               1. ANN MLP
               1. K-NN
               1. K-Means
            1. Text Module in OpenCV Contrib
         1. Tutorial Series on using OpenVINO models and DLDT toolkit.
      * ***Skills Required:*** Excellent written English, Mastery level C++ knowledge, college course work in Computer Vision, Python knowledge. Working knowledge of deep neural networks.
      * ***Mentors:*** Vikas Gupta
      * ***Difficulty:*** Easy 

1. ### Area: User Interface
   1. #### _IDEA:_ Improve the OpenCV user interface
      * ***Description:*** [HighGUI](https://docs.opencv.org/master/d7/dfc/group__highgui.html) is OpenCV's graphical user interface including event triggering. It's cool, but it's old and needs revamping. HighGUI has been improved by using a QT interface at the cost of a large library to link in. We want to replace the QT functionality (mainly zoom to pixel and snapshot) with custom code. We'd also like to add native buttons.
      * ***Expected Outcomes:*** 
         * Drop QT dependency but retain at least zoom to pixel and snapshot capability with custom code
         * Add buttons as a native capability
         * Allow setting up an adaptive array of display windows w/in one larger window.
         * Retain ability for Python to call HighGUI
         * Resources
            * [High GUI documentation](https://docs.opencv.org/master/d7/dfc/group__highgui.html)
            * [High GUI tutorial](https://docs.opencv.org/3.4.0/d0/de2/tutorial_table_of_content_highgui.html)
      * ***Skills Required:*** C++, Python, user interface experience
      * ***Mentors:*** Vadim Pisarevsky
      * ***Difficulty:*** Easy if you are well familiar with GUI, Medium if not.

----

* ## **All Ideas Above**
   1. #### Have these Additional Expected Outcomes:
      * Use the [OpenCV How to Contribute](https://github.com/opencv/opencv/wiki/How_to_contribute) and [Aruco module in opencv_contrib](https://github.com/opencv/opencv_contrib/tree/master/modules/aruco) as a guide.
      * Add unit tests [described here](https://github.com/opencv/opencv/wiki/QA_in_OpenCV), see also the [Aruco test example](https://github.com/opencv/opencv_contrib/tree/master/modules/aruco/test)
      * Add a tutorial, and sample code 
         * see the [Aruco tutorials](https://github.com/opencv/opencv_contrib/tree/master/modules/aruco/tutorials) and how they [look on the web](https://docs.opencv.org/master/d9/d6d/tutorial_table_of_content_aruco.html).
         * See the [Aruco samples](https://github.com/opencv/opencv_contrib/tree/master/modules/aruco/samples)
      * Make a short video showing off your algorithm and post it to Youtube. [Here's an Example](https://www.youtube.com/watch?v=O5P65CYqo_Q).

------------------

General Information:
--------------------
[ ▶️  **Join our OpenCV GSoC 2019 Mailing List** ◀️ ](https://groups.google.com/d/forum/opencv-gsoc-2019)
-  [Program Site for GSoC 2019](https://summerofcode.withgoogle.com/)
- [Mailing list for OpenCV GSOC 2019](https://groups.google.com/d/forum/opencv-gsoc-2019): `opencv-gsoc-2019@googlegroups.com`
- IRC Channel: `#opencv` on freenode
- **Timelines**
    - [Timeline for GSoC 2019](https://summerofcode.withgoogle.com/how-it-works/#timeline)


### Important dates:

 Date (2019)              | Description                                                    | Comment
:------------------------:| -------------------------------------------------------------- | --------------
January 15        |Mentoring organizations begin submitting applications to Google  | :ok:
Feb 6	  | Mentoring organization application deadline                 | :ok:
February 26  | [Organizations Announced](https://summerofcode.withgoogle.com/organizations/5654472617885696/)  | :+1: [**We are in!**]( https://summerofcode.withgoogle.com/organizations/5654472617885696/)
Feb 27 - Mar 24 | [Talk to us](https://groups.google.com/d/forum/opencv-gsoc-2019) |
March 25 - April 9         | [Apply to OpenCV through GSoC](https://summerofcode.withgoogle.com/)            |
April 9 - May 6   | Application Review Period        |
May 6	  | Student Projects Announced by GSoC                              |
May 6 - 27	  | Community Bonding                                |
May 27 - ...	  | _Coding ..._                           |
June 24-28  | **Evaluation #1**                                                                          |
June 24 - ...	    | _Coding Continues ..._  |
July 22-26	  | **Evaluation #2**   |
July 22 - Aug 19	  | _Coding Continues ..._                                 |
Aug 19-26	          | Students submit final code and their evaluations       |
Aug 26-Sept 2	  | Mentors submit their **Final evaluation**   |
Sept 3	  | Results announced                                 |


### Times:

UTC to PDT (California uses PST in the winter (from Nov 1st) and PDT in the summer (from March 8)).

[UTC time](https://time.is/UTC)

[UTC time converter](http://www.timebie.com/std/gmt.php)

### Resources:

- [OpenCV Project Ideas List](https://github.com/opencv/opencv/wiki/GSoC_2019#OpenCV-project-ideas-list)
- [OpenCV official Site](https://opencv.org)
- [OpenCV wiki](https://github.com/opencv/opencv/wiki)
- [Questions and Answers](http://answers.opencv.org/questions/)
- [[How to do a pull request/How to Contribute Code|How_to_contribute]]
- Source Code can be found at [GitHub/opencv](https://github.com/opencv/opencv) and [GitHub/opencv_contrib](https://github.com/opencv/opencv_contrib)
- [[Developer meeting notes|Meeting_notes]]
- [Mentor Only Mailing List](https://groups.google.com/forum/#!forum/opencv_mentors_2019)
- [Student+Mentor Mailing List](https://groups.google.com/forum/#!forum/opencv-gsoc-2019)

Student Info
-------------------------------------



* ## **How students will be evaluated once working:**

- Student projects to be paid only if:
    - **Phase 1:**
        - You must generate a pull request
            - That builds
            - Has at least stubbed out _(place holder functions such as just displaying an image)_ functionality
            - With OpenCV appropriate Doxygen documentation ([example tutorial](http://flcwiki.desy.de/How%20to%20document%20your%20code%20using%20doxygen))
                - Includes What the function or net is, what the function or net is used for 
            - Has at least stubbed out unit test
            - Has a stubbed out example/tutorial of use that builds
                 - See [the contribution guild](https://github.com/opencv/opencv/wiki/How_to_contribute)
                 - and [the coding style guild](https://github.com/opencv/opencv/wiki/Coding_Style_Guide)
                 - the [line_descriptor](https://github.com/opencv/opencv_contrib/tree/master/modules/line_descriptor) is a good example of student code
    - **Phase 2:**
        - You must generate a pull request
            - That builds
            - Has basic functionality
            - With OpenCV appropriate Doxygen documentation
                - Includes What the function or net is, what the function or net is used for 
            - Has basic unit test
            - Has a tutorial of how to use the function or net and why you'd want to use it.
    - **End of summer:**
        - A full pull request
            - Full Doxygen documentation
            - A good unit test
            - Example of use/tutorial of the code or net
        - Create a (short!) Movie (preferably on Youtube, but any movie) that demonstrates your code
            - We use this to create an overall summary. Past years:
                - [The 2015 Movie](https://www.youtube.com/watch?v=OUbUFn71S4s)
                - [The 2014 Movie](https://www.youtube.com/watch?v=3f76HCHJJRA)
                - [The 2013 Movie](https://www.youtube.com/watch?v=_TTtN4frMEA)


-----

For computer vision professionals interested in mentoring
---------------------------------------------------------

1.  Contact us by March 25th on the opencv-gsoc googlegroups mailing list above and ask to be a mentor (or we will ask you in some known cases)
2.  If we accept you, we will post a request from the Google Summer of Code OpenCV project site asking you to join.
3.  You must accept the request and **you are a mentor!**
   * You will also need to get on:
       * [The Mentor Only Mailing List](https://groups.google.com/forum/#!forum/opencv_mentors_2019)
       * [The Student+Mentor Mailing List](https://groups.google.com/forum/#!forum/opencv-gsoc-2019)
4.  You then:
    - Look through the [ideas above](https://github.com/opencv/opencv/wiki/GSoC_2019#opencv-project-ideas-list), choose one you'd like to mentor or create your own and post it for discussion on the mentor list.
    - Go to the opencv-gsoc googlegroups mailing list above and look through student project proposals and discussions. Discuss the ideas you've chosen. 
       - Find likely students, ask [them to apply](https://github.com/opencv/opencv/wiki/GSoC_2019#how-to-apply) to your project(s)
    - You will get a list of students who have applied to your project. Go through them and select a student or rejecting them all if none suits and joining to co-mentor or to quit this year are acceptable outcomes.
       - Make sure your students officially apply through the [Google Summer of Code site](https://summerofcode.withgoogle.com) before April 9th.
5.  Then, when we get a slot allocation from Google, the administrators *"spend"* the slots in order of priority influenced by whether there's a capable mentor or not for each topic.
6.  Students must finally actually accept to do that project (some sign up for multiple organizations and then choose)
7. Get to work!

**If** you are accepted as a mentor **and** you find a suitable student **and** we give you a slot **and** the student signs up for it, **then** you are an actual mentor! Otherwise you are **not a mentor** and have no other obligations. 
   - Thank you for trying. 
   - You may contact other mentors and co-mentor a project.

You get paid a modest stipend over the summer to mentor, typically $500 minus an org fee of 6%.

Several mentors donate their salary, earning ever better positions in heaven when that comes.

-------------------------------------------------------------------------------------------------
# Staff

## Mentors
Mentors are encouraged to look at the ideas list above and choose from that. If you have a specific idea that you are passionate about, then use the github Markdown template below and submit to the mentor's mailing list so that we can see if it should be posted.

```
### Template
1. ### <Descriptive Category such as "Deep Nets">
   1. #### _IDEA:_ <Descriptive Title>
      * ***Description:*** 3-7 sentences describing the task
      * ***Expected Outcomes:*** 
         * < Short bullet list describing what is to be accomplished >
         * <i.e. create a new module called "bla bla">
         * < Has method to accomplish X >
         * <...>
         * Resources
            * [For example a paper citation](https://arxiv.org/pdf/1802.08091.pdf)
            * [For example an existing feature request](https://github.com/opencv/opencv/issues/11013)
            * [Possibly an existing related module](https://github.com/opencv/opencv_contrib/tree/master/modules/optflow) that includes some new optical flow algorithms.
      * ***Skills Required:*** < for example: mastery plus experience coding in C++, college course work in vision that covers optical flow, python. Best if you have also worked with deep neural networks. >
      * ***Mentors:*** < your name goes here >
      * ***Difficulty:*** <Easy, Medium, Hard> 
```


### Accepted Projects and Mentors


Alphabetic by project title

Student | Title | Mentor(s)
--------|-------|-----------

#### Mentors
```
Michael Tetelman	
Edgar Riba	
Vincent Rabaud
Steven Puttemans
Gholamreza Amayeh
Justin Shenk
Stefano Fabri
Satya Mallick
Davis King
Sunita Naya
Dmitry Matveev
Grace Vesom
Vladimir Tyan
Jiri Hörne
Vitaly Tuzov
Ankit Sachan
Yida Wang
Dmitry Kurtaev
Vikas Gupta
```

## Admins

```
Gary Bradski
Vadim Pisarevsky
Shiqi Yu
```
